# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, ProFatXuanAll
# This file is distributed under the same license as the Language Model
# Playground package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Language Model Playground 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-10-13 16:38+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../source/lmp/script/train_tokenizer.py.rst:2
msgid ":py:mod:`lmp.script.train_tokenizer`"
msgstr ""

#: lmp.script.train_tokenizer:1 of
msgid "Train tokenizer."
msgstr ""

#: lmp.script.train_tokenizer:3 of
msgid ""
"Tool for training tokenizer on particular dataset. This script is usually"
" run before training model."
msgstr ""

#: lmp.script.train_tokenizer:9 of
msgid ":obj:`lmp.script.tokenize`"
msgstr ""

#: lmp.script.train_tokenizer:9 of
msgid "Use pre-trained tokenizer to tokenize text."
msgstr ""

#: lmp.script.train_tokenizer:11 of
msgid ":obj:`lmp.tknzr`"
msgstr ""

#: lmp.script.train_tokenizer:12 of
msgid "All available tokenizers."
msgstr ""

#: lmp.script.train_tokenizer:15 of
msgid "Examples"
msgstr ""

#: lmp.script.train_tokenizer:16 of
msgid ""
"The following example train :py:class:`lmp.tknzr.WsTknzr` "
"(``whitespace``) on :py:class:`lmp.dset.WikiText2Dset` using ``train`` "
"version. (``--dset_name wikitext-2`` and ``--ver train``)."
msgstr ""

#: lmp.script.train_tokenizer:29 of
msgid ""
"The training result will be save at ``exp/my_exp``, and can be reused by "
"other scripts."
msgstr ""

#: lmp.script.train_tokenizer:32 of
msgid "One can include more tokens in vocabulary using ``--max_vocab``:"
msgstr ""

#: lmp.script.train_tokenizer:43 of
msgid "Set ``--max_vocab`` to ``-1`` to include all tokens in the dataset:"
msgstr ""

#: lmp.script.train_tokenizer:54 of
msgid ""
"Use ``--min_count`` to filter out tokens such as typos, names, locations,"
" etc."
msgstr ""

#: lmp.script.train_tokenizer:65 of
msgid ""
"Use ``--is_uncased`` to avoid differ tokens with same charaters but in "
"different case."
msgstr ""

#: lmp.script.train_tokenizer:78 of
msgid "Use ``-h`` or ``--help`` options to get list of available tokenizers."
msgstr ""

#: lmp.script.train_tokenizer.main:1 of
msgid "Script entry point."
msgstr ""

#: lmp.script.train_tokenizer.parse_arg:1 of
msgid "Parse arguments from CLI."
msgstr ""

#: lmp.script.train_tokenizer.parse_arg:3 of
msgid ""
"Argument must begin with a tokenizer name ``tknzr_name``. All arguments "
"are added with tokenizer's static method ``train_parser``."
msgstr ""

#: lmp.script.train_tokenizer.parse_arg of
msgid "Returns"
msgstr ""

#: lmp.script.train_tokenizer.parse_arg:6 of
msgid "Arguments from CLI."
msgstr ""

#: lmp.script.train_tokenizer.parse_arg of
msgid "Return type"
msgstr ""

