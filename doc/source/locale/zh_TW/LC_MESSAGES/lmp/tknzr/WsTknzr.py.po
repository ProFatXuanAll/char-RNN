# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, ProFatXuanAll
# This file is distributed under the same license as the Language Model
# Playground package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Language Model Playground 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-10-13 16:38+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../source/lmp/tknzr/WsTknzr.py.rst:2
msgid ":py:class:`lmp.tknzr.WsTknzr`"
msgstr ""

#: lmp.tknzr._ws.WsTknzr:1 of
msgid "Whitespace :term:`tokenizer` class."
msgstr ""

#: lmp.tknzr._ws.WsTknzr:3 of
msgid ""
"Tokenize text into (unicode) whitespace seperate tokens. No whitespace "
"will be preserved after tokenization."
msgstr ""

#: lmp.tknzr._ws.WsTknzr lmp.tknzr._ws.WsTknzr.dtknz lmp.tknzr._ws.WsTknzr.tknz
#: of
msgid "Parameters"
msgstr ""

#: lmp.tknzr._ws.WsTknzr:6 of
msgid "Convert text into lowercase if set to ``True``."
msgstr ""

#: lmp.tknzr._ws.WsTknzr:8 of
msgid ""
"Maximum vocabulary size. Set to ``-1`` to include as many tokens as "
"possible in vocabulary."
msgstr ""

#: lmp.tknzr._ws.WsTknzr:11 of
msgid ""
"Minimum token frequency for each token to be included in tokenizer's "
"vocabulary."
msgstr ""

#: lmp.tknzr._ws.WsTknzr:14 of
msgid ""
"Token (a string) to id (an integer) lookup table. If ``tk2id is not "
"None``, then initialize lookup table with ``tk2id``. Otherwise initialize"
" lookup table with special tokens only."
msgstr ""

#: lmp.tknzr._ws.WsTknzr:18 of
msgid "Useless parameter. Intently left for subclass parameters extension."
msgstr ""

#: lmp.tknzr._ws.WsTknzr:24 of
msgid "Tokenizer name is ``whitespace``. Used for command line argument parsing."
msgstr ""

#: lmp.tknzr._ws.WsTknzr of
msgid "type"
msgstr ""

#: lmp.tknzr._ws.WsTknzr:27 of
msgid "ClassVar[str]"
msgstr ""

#: lmp.tknzr._ws.WsTknzr of
msgid "Raises"
msgstr ""

#: lmp.tknzr._ws.WsTknzr:29 of
msgid "When parameters do not obey their type annotations."
msgstr ""

#: lmp.tknzr._ws.WsTknzr:31 of
msgid ":obj:`lmp.tknzr.BaseTknzr`"
msgstr ""

#: lmp.tknzr._ws.WsTknzr:34 lmp.tknzr._ws.WsTknzr.dtknz:15
#: lmp.tknzr._ws.WsTknzr.tknz:16 of
msgid "Examples"
msgstr ""

#: lmp.tknzr._ws.WsTknzr.dtknz:1 of
msgid "Convert :term:`tokens` back to text."
msgstr ""

#: lmp.tknzr._ws.WsTknzr.dtknz:3 of
msgid ""
"Tokens will be joined with one whitespace. Returned text is normalized by"
" :py:meth:`lmp.tknzr.BaseTknz.norm`."
msgstr ""

#: lmp.tknzr._ws.WsTknzr.dtknz:6 of
msgid "Sequence of tokens to be detokenized."
msgstr ""

#: lmp.tknzr._ws.WsTknzr.dtknz lmp.tknzr._ws.WsTknzr.tknz of
msgid "Returns"
msgstr ""

#: lmp.tknzr._ws.WsTknzr.dtknz:9 of
msgid "Normalized text with whitespaces in between each token."
msgstr ""

#: lmp.tknzr._ws.WsTknzr.dtknz lmp.tknzr._ws.WsTknzr.tknz of
msgid "Return type"
msgstr ""

#: lmp.tknzr._ws.WsTknzr.dtknz:12 of
msgid ":obj:`lmp.tknzr.WsTknzr.tknz`, :obj:`lmp.tknzr.BaseTknzr.norm`"
msgstr ""

#: lmp.tknzr._ws.WsTknzr.tknz:1 of
msgid "Perform whitespace :term:`tokenization` on text."
msgstr ""

#: lmp.tknzr._ws.WsTknzr.tknz:3 of
msgid ""
"Text will first be normalized by :py:meth:`lmp.tknzr.BaseTknz.norm`, then"
" be tokenized by whitespaces."
msgstr ""

#: lmp.tknzr._ws.WsTknzr.tknz:6 of
msgid "Text to be tokenized."
msgstr ""

#: lmp.tknzr._ws.WsTknzr.tknz:9 of
msgid ""
"List of normalized whitespace-separated tokens. No whitespaces will be "
"preserved after tokenization."
msgstr ""

#: lmp.tknzr._ws.WsTknzr.tknz:13 of
msgid ":obj:`lmp.tknzr.WsTknzr.dtknz`, :obj:`lmp.tknzr.BaseTknzr.norm`"
msgstr ""

