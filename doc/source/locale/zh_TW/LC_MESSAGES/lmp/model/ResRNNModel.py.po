# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, ProFatXuanAll
# This file is distributed under the same license as the Language Model
# Playground package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Language Model Playground 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-10-13 16:38+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../source/lmp/model/ResRNNModel.py.rst:2
msgid ":py:class:`lmp.model.ResRNNModel`"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:1 of
msgid "RNN language model with residual connection."
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:3 of
msgid ""
"Same architecture as :py:class:`lmp.model.RNNModel` but use residual "
"connection on RNN layer."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock lmp.model._res_rnn.ResRNNBlock.forward
#: lmp.model._res_rnn.ResRNNModel lmp.model._res_rnn.ResRNNModel.forward of
msgid "Parameters"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:6 of
msgid "Token embedding dimension. Must be bigger than or equal to ``1``."
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:9 of
msgid ""
"Hidden dimension for Feed-Forward layers and residual connected RNN "
"layers. Must be bigger than or equal to ``1``."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:35 lmp.model._res_rnn.ResRNNModel:13 of
msgid "Useless parameter. Intently left for subclass parameters extension."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:38 lmp.model._res_rnn.ResRNNModel:16 of
msgid ""
"Number of residual connected RNN layers. Must be bigger than or equal to "
"``1``."
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:19 of
msgid ""
"Number of Feed-Forward layers after residual connected RNN layers. All "
"layers are paired with ReLU activatons except for the last one. Must be "
"bigger than or equal to ``1``."
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:23 of
msgid ""
"Number of Feed-Forward layers before residual connected RNN layers. All "
"layers are paired with ReLU activatons. Must be bigger than or equal to "
"``1``."
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:27 of
msgid ""
"Dropout probability for token embeddings. Must satisfy ``0.0 <= p_emb <= "
"1.0``."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:41 lmp.model._res_rnn.ResRNNModel:30 of
msgid ""
"Dropout probability for every hidden representations. Must satisfy ``0.0 "
"<= p_hid <= 1.0``."
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:33 of
msgid "Tokenizer instance with attributes ``pad_tkid`` and ``vocab_size``."
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:38 of
msgid "Token embedding lookup matrix. Use token ids to lookup token embeddings."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock lmp.model._res_rnn.ResRNNModel of
msgid "type"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:41 of
msgid "torch.nn.Embedding"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:45 of
msgid ""
"Token embedding dropout. Drop embedding features with probability "
"``p_emb``."
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:48 of
msgid "torch.nn.Dropout"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:52 of
msgid ""
"Residual connected RNN which encode temporal features. Each time step's "
"hidden state depends on current input and previous hidden state. Drop "
"temporal features with probability ``p_hid``."
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:57 of
msgid "lmp.model.ResRNNBlock"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:61 of
msgid "Model name is ``res-RNN``. Used for command line argument parsing."
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:64 of
msgid "ClassVar[str]"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:68 of
msgid ""
"Rectified Feed-Forward layers which transform temporal features from "
"hidden dimension ``d_hid`` to embedding dimension ``d_emb``. Drop "
"rectified units with probability ``p_hid``."
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:72 lmp.model._res_rnn.ResRNNModel:80 of
msgid "torch.nn.Sequential"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel:76 of
msgid ""
"Rectified Feed-Forward layers which transform token embeddings from "
"embedding dimension ``d_emb`` to hidden dimension ``d_hid``. Drop "
"rectified units with probability ``p_hid``."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward:1
#: lmp.model._res_rnn.ResRNNModel.forward:1 of
msgid "Perform forward pass."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward:3
#: lmp.model._res_rnn.ResRNNModel.forward:3 of
msgid "Forward pass algorithm is structured as follow:"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel.forward:5 of
msgid "Input batch of previous token ids. (shape: ``(B, S)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel.forward:7 of
msgid ""
"Use batch of previous token ids to perform token embeddings lookup on "
"``self.emb``. (shape: ``(B, S, E)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel.forward:10 of
msgid ""
"Use ``self.emb_dp`` to drop some features in token embeddings. (shape: "
"``(B, S, E)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel.forward:12 of
msgid ""
"Use ``self.pre_hid`` to transform token embeddings from embedding "
"dimension ``E`` to hidden dimension ``H``. (shape: ``(B, S, H)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel.forward:15 of
msgid "Use ``self.hid`` to encode temporal features. (shape: ``(B, S, H)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel.forward:17 of
msgid ""
"Use ``self.post_hid`` to transform temporal features from hidden "
"dimension ``H`` to embedding dimension ``E``. (shape: ``(B, S, E)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel.forward:20 of
msgid ""
"Find the most possible next token id in embedding matrix ``self.emb`` "
"using inner product. This reduce parameters since we share weight on "
"token embedding and output projection. (shape: ``(B, S, V)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel.forward:25 of
msgid ""
"Return logits. Used with ``self.pred`` to convert logit into prediction. "
"Used wtih ``self.loss_fn`` to perform optimization. (shape: ``(B, S, "
"V)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel.forward:30 of
msgid ""
"Batch of previous token ids encoded by :py:class:`lmp.tknzr.BaseTknzr` "
"subclass instance. ``batch_prev_tkids`` has shape ``(B, S)`` and ``dtype "
"== torch.int64``."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward
#: lmp.model._res_rnn.ResRNNModel.forward of
msgid "Returns"
msgstr ""

#: lmp.model._res_rnn.ResRNNModel.forward:36 of
msgid ""
"Next token logits for each token id in batch. Logits has shape ``(B, S, "
"V)`` and ``dtype == torch.float32``."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward
#: lmp.model._res_rnn.ResRNNModel.forward of
msgid "Return type"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:1 of
msgid "Residual connected RNN blocks."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:3 of
msgid ""
"Each output of RNN will be added with its input and then dropout with "
"probability ``p_hid``. Residual connection are used as follow:"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:7 of
msgid ""
"\\begin{align*}\n"
"t &\\in [1, S] \\\\\n"
"l &\\in [1, L] \\\\\n"
"h_0^l &= 0 \\\\\n"
"h_t^l &= \\text{RNN}(x_t^l, h_{t-1}^l) \\\\\n"
"y_t^l &= h_t^l + x_t^l \\\\\n"
"x_t^{l+1} &= y_t^l\n"
"\\end{align*}"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:18 of
msgid ""
"Where :math:`S` means sequence length, :math:`L` means number of layer "
"(same as ``n_hid_lyr``), :math:`x_t^l` means input sequence time step "
":math:`t` at layer :math:`l`, :math:`h_t^l` means hidden representation "
"time step :math:`t` encoded by recurrent layer :math:`l`, :math:`h_0^l` "
"means initial hidden representation of recurrent layer :math:`l`, "
":math:`y_t^l` is the output of time step :math:`t` at layer :math:`l`."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:25 of
msgid ""
"For comment throughout this class and its subclasses, we use the "
"following symbols to denote the shape of tensors:"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:28 of
msgid "``B``: Batch size."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:29 of
msgid "``H``: Hidden representation dimension."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:30 of
msgid "``S``: Length of sequence of tokens."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:32 of
msgid ""
"Hidden dimension for residual connected RNN. Must be bigger than or equal"
" to ``1``."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:47 of
msgid ""
"Drop each output temporal features of ``self.recur`` with probability "
"``p_hid``. Do not dropout last temporal features output from "
"``self.recur[-1]`` since :py:class:`lmp.model.ResRNNModel` have "
"``self.post_hid`` which drop output of ``self.hid``."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:53 of
msgid "torch.nn.ModuleList[torch.nn.Dropout]"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:57 of
msgid ""
"List of vanilla RNN which encode temporal features. Each time step's "
"hidden state depends on current input and previous hidden state."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock:61 of
msgid "torch.nn.ModuleList[torch.nn.RNN]"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward:5 of
msgid ""
"Input batch of previous token hidden representations. (shape: ``(B, S, "
"H)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward:7 of
msgid ""
"Pair block and dropouts in ``self.recur`` and ``self.dp``. Pair only "
"first ``n_hid_lyr - 1`` blocks and dropouts. Use for-loop to perform the "
"following operations:"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward:11 of
msgid "Use paired block to encode temporal features. (shape: ``(B, S, H)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward:13 of
msgid "Add input and output of paired block. (shape: ``(B, S, H)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward:15 of
msgid ""
"Use paired dropout to drop some features. This step is skipped on last "
"for loop step. (shape: ``(B, S, H)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward:18 of
msgid "Use sparse features as input of next loop."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward:20 of
msgid "Return final output. (shape: ``(B, S, H)``)"
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward:23 of
msgid ""
"Batch of previous token hidden representation. ``batch_tk_reps`` has "
"shape ``(B, S, H)`` and ``dtype == torch.float32``."
msgstr ""

#: lmp.model._res_rnn.ResRNNBlock.forward:28 of
msgid "Temporal features with shape ``(B, S, H)`` and ``dtype == torch.float32``."
msgstr ""

