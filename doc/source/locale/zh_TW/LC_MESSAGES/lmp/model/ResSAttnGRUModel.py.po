# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020, ProFatXuanAll
# This file is distributed under the same license as the Language Model
# Playground package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Language Model Playground 1.0.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-10-13 16:38+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.1\n"

#: ../../source/lmp/model/ResSAttnGRUModel.py.rst:2
msgid ":py:class:`lmp.model.ResSAttnGRUModel`"
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:1 of
msgid "Residual connected GRU language model with self attention mechanism."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:3 of
msgid ""
"Same architecture as :py:class:`lmp.model.ResSAttnRNNModel` but replace "
"residual connected self attention RNN with residual connected self "
"attention GRU instead."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUBlock
#: lmp.model._res_sattn_gru.ResSAttnGRUModel of
msgid "Parameters"
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:7 of
msgid "Token embedding dimension. Must be bigger than or equal to ``1``."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:10 of
msgid ""
"Hidden dimension for Feed-Forward layers and residual connected self "
"attention GRU layers. Must be bigger than or equal to ``1``."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUBlock:10
#: lmp.model._res_sattn_gru.ResSAttnGRUModel:14 of
msgid "Useless parameter. Intently left for subclass parameters extension."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUBlock:13
#: lmp.model._res_sattn_gru.ResSAttnGRUModel:17 of
msgid ""
"Number of residual connected self attention GRU layers. Must be bigger "
"than or equal to ``1``."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:20 of
msgid ""
"Number of Feed-Forward layers after residual connected self attention GRU"
" layers. All layers are paired with ReLU activatons except for the last "
"one. Must be bigger than or equal to ``1``."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:25 of
msgid ""
"Number of Feed-Forward layers before residual connected self attention "
"GRU layers. All layers are paired with ReLU activatons. Must be bigger "
"than or equal to ``1``."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:30 of
msgid ""
"Dropout probability for token embeddings. Must satisfy ``0.0 <= p_emb <= "
"1.0``."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUBlock:16
#: lmp.model._res_sattn_gru.ResSAttnGRUModel:33 of
msgid ""
"Dropout probability for every hidden representations. Must satisfy ``0.0 "
"<= p_hid <= 1.0``."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:36 of
msgid "Tokenizer instance with attributes ``pad_tkid`` and ``vocab_size``."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:41 of
msgid ""
"Self attention GRU with residual connection which encode temporal "
"features. Each time step's hidden state depends on current input and "
"previous hidden state. Drop temporal features with probability ``p_hid``."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel of
msgid "type"
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:47 of
msgid "lmp.model.SAttnGRUBlock"
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:51 of
msgid "Model name is ``res-sattn-GRU``. Used for command line argument parsing."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUModel:54 of
msgid "ClassVar[str]"
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUBlock:1 of
msgid "Residual connected GRU block with self attention mechanism."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUBlock:3 of
msgid ""
"Same architecture as :py:class:`lmp.model.ResSAttnRNNBlock` but replace "
"RNN with GRU instead."
msgstr ""

#: lmp.model._res_sattn_gru.ResSAttnGRUBlock:6 of
msgid ""
"Hidden dimension for GRU and self attention linear transformation weights"
" (including query, key, value and output). Must be bigger than or equal "
"to ``1``."
msgstr ""

